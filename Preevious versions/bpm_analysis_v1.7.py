from scipy.io import wavfile
from scipy import signal
import numpy as np
import matplotlib.pyplot as plt
import plotly.graph_objects as go
import sys
import warnings

# Load audio data
import os

# Read any .wav file inside the "input_data" folder
wav_files = [f for f in os.listdir("input_data") if f.endswith('.wav')]
if not wav_files:
    raise FileNotFoundError("No .wav files found in the 'input_data' folder")

# Use the first .wav file found
wav_file_path = os.path.join("input_data", wav_files[0])

#ignore warning generated by the wavfile.read function. can most likely ignore
with warnings.catch_warnings():
    warnings.simplefilter("ignore")
    sample_rate, audio_data = wavfile.read(wav_file_path)

# Convert to mono if it's stereo
if len(audio_data.shape) == 2:
    audio_data_mono = np.mean(audio_data, axis=1).astype(np.int16)
else:
    audio_data_mono = audio_data

# Calculate rolling average and standard deviation
window_time = 0.5  # can adjust, window of time to  calculate average and std deviation, in seconds
window_size = int(window_time * sample_rate)
rolling_avg = signal.fftconvolve(np.abs(audio_data_mono), np.ones(window_size) / window_size, mode='same')
rolling_std = signal.fftconvolve(np.abs(audio_data_mono - rolling_avg), np.ones(window_size) / window_size, mode='same') ** 0.5

# Perform local normalization
alpha = .2  # can adjust, higher for weaker normalization, default .2
audio_data_normalized = (audio_data_mono - rolling_avg) / (rolling_std + alpha)

# Length of the audio in seconds
audio_length_seconds = len(audio_data_normalized) / sample_rate

# Create an array of time windows for calculating BPM
time_windows = np.arange(0, audio_length_seconds - 5, 1)

# Initialize variables
s1_s2_Divider = 1 #(1) if s1 or s2 is signifigantly louder, (2) if both beats are detected
threshold_multiplier = 2.5 # can adjust, higher for higher threshold, default 2
cooldown_multiplier = 0.7 # can adjust, xx% of the time between each beat, default .7
max_bpm = 220 # can adjust, clamps detection range
min_bpm = 40 # can adjust
smart_peaks = []#detected peaks
current_bpm = 120  # Initialize with a reasonable default
dynamic_threshold = np.mean(np.abs(audio_data_normalized)) * threshold_multiplier

# Initialize next_peak_allowed_time array
next_peak_allowed_time = np.zeros(len(audio_data_normalized))

# Initialize a variable to keep track of whether the BPM is valid and smoothed BPM
smoothed_bpm = None
smoothing_factor = 0.8  # can adjust, higher = the average more sensitive, default 0.7

# Loop through the audio data to perform smart peak detection
for i in range(len(audio_data_normalized) - 1):
    valid_bpm = True
    current_time = i / sample_rate
    current_amplitude = audio_data_normalized[i]
  
    if current_time >= next_peak_allowed_time[i]:
        if current_amplitude > dynamic_threshold: #maybe consider abs(current_amplitude) for both sides of the waveform
            # Detected a peak
            smart_peaks.append(i)
            
            # Update current_bpm based on last two peaks
            if len(smart_peaks) >= 2:
                time_between_peaks = (smart_peaks[-1] - smart_peaks[-2]) / sample_rate
                current_bpm = 60 / time_between_peaks
                if current_bpm < min_bpm or current_bpm > max_bpm:
                    # Invalid BPM, set a flag
                    valid_bpm = False
                # Apply smoothing
                if smoothed_bpm is None:
                    smoothed_bpm = current_bpm
                else:
                    smoothed_bpm = (smoothing_factor * smoothed_bpm) + ((1 - smoothing_factor) * current_bpm)
            # Update next_peak_allowed_time to enforce cooldown
            if valid_bpm and smoothed_bpm is not None:
                cooldown_samples = int(sample_rate * (60 / smoothed_bpm) * cooldown_multiplier)
            else:
                # Set a default cooldown time if BPM is not valid
                default_cooldown_time = 0.45  # in seconds, can adjust, default 0.4
                cooldown_samples = int(sample_rate * default_cooldown_time)
                
            next_allowed_time = current_time + (cooldown_samples / sample_rate)
            next_peak_allowed_time[i:i+cooldown_samples] = next_allowed_time

# Convert to a NumPy array for easier manipulation
smart_peaks = np.array(smart_peaks)
smart_peaks = np.unique(smart_peaks)

# Exit Script if no peaks detected
if smart_peaks.size == 0:
    print("No peaks detected")
    sys.exit()

# Calculate time instances for these smartly detected peaks
smart_peak_times = smart_peaks / sample_rate

# Initialize array to store smart BPM values
smart_bpm_values = []

# Calculate BPM for each time window using smart peaks
for start_time in time_windows:
    end_time = start_time + 5
    peaks_in_window = smart_peak_times[(smart_peak_times >= start_time) & (smart_peak_times < end_time)]
    if len(peaks_in_window) >= 2:
        avg_bpm = (60 * len(peaks_in_window) / (peaks_in_window[-1] - peaks_in_window[0])) / s1_s2_Divider
        smart_bpm_values.append(avg_bpm)
    else:
        smart_bpm_values.append(np.nan)

# Visualization
segment_start = 100  # Start time in seconds
segment_end = 200  # End time in seconds
segment_start_sample = int(segment_start * sample_rate)
segment_end_sample = int(segment_end * sample_rate)

# Create the figure
fig = go.Figure()

# Add the waveform trace
fig.add_trace(go.Scatter(
    x=np.arange(segment_start_sample, segment_end_sample) / sample_rate,
    y=audio_data_mono[segment_start_sample:segment_end_sample],
    mode='lines',
    name='Waveform'
))

# Add the peaks trace
segment_smart_peaks = smart_peaks[(smart_peaks >= segment_start_sample) & (smart_peaks < segment_end_sample)]
fig.add_trace(go.Scatter(
    x=segment_smart_peaks / sample_rate,
    y=audio_data_mono[segment_smart_peaks],
    mode='markers',
    marker=dict(size=10, color='red'),
    name='Peaks'
))

# Layout customization
fig.update_layout(
    title="Detected Peaks in Segment",
    xaxis_title="Time (s)",
    yaxis_title="Amplitude",
    xaxis=dict(
        rangeslider=dict(
            visible=True
        ),
        type="linear"
    ),
    dragmode='pan'
)

# Show the figure
fig.show(config={'scrollZoom': True})

# Plot smart BPM over time
fig, ax1 = plt.subplots(figsize=(15, 6))
ax1.plot(time_windows, smart_bpm_values, marker='o', linestyle='-')

# Create a second x-axis
ax2 = ax1.twiny()

# Calculate the labels and positions for the new x-axis
axis_interval = 10 # can adjust graph axis display, in seconds
xticks_positions = range(0, int(max(time_windows)), axis_interval)
xticks_labels = [f"{int(tick//60):02d}:{int(tick%60):02d}" for tick in xticks_positions]

# Apply the new x-axis labels and positions to the second axis
ax2.set_xticks(xticks_positions)
ax2.set_xticklabels(xticks_labels)

# Label both axes
ax1.set_xlabel('Time (s)')
ax2.set_xlabel('Time (min:sec)')
ax1.set_ylabel('BPM')

# Add horizontal lines
for y in range(0, int(np.ceil(max(smart_bpm_values) / 60)) * 60 + 1, 60):
    ax1.axhline(y, color='gray', linestyle='--', linewidth=0.5)

plt.title('BPM Over Time')
plt.grid(True)
plt.show()